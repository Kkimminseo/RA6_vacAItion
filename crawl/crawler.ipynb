{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "# 웹드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(3)\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "\n",
    "\n",
    "# Naver API key 입력\n",
    "client_id = os.getenv(\"NAVER_ID\")\n",
    "client_secret = os.getenv(\"NAVER_SECRET\")\n",
    "\n",
    "\n",
    "# selenium으로 검색 페이지 불러오기 #\n",
    "naver_urls = []\n",
    "postdate = []\n",
    "titles = []\n",
    "\n",
    "# 검색어 입력\n",
    "keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "encText = urllib.parse.quote(keword)\n",
    "\n",
    "# 검색을 끝낼 페이지 입력\n",
    "end = input(\"\\n크롤링을 끝낼 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "if end == \"\":\n",
    "    end = 1\n",
    "else:\n",
    "    end = int(end)\n",
    "print(\"\\n 1 ~ \", end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "\n",
    "# 한번에 가져올 페이지 입력\n",
    "display = input(\"\\n한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\")\n",
    "if display == \"\":\n",
    "    display = 10\n",
    "else:\n",
    "    display = int(display)\n",
    "print(\"\\n한번에 가져올 페이지 : \", display, \"페이지\")\n",
    "\n",
    "\n",
    "for start in range(end):\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + \"&start=\" + str(start+1) + \"&display=\" + str(display+1) # JSON 결과\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        \n",
    "        data = json.loads(response_body.decode('utf-8'))['items']\n",
    "        for row in data:\n",
    "            if('blog.naver' in row['link']):\n",
    "                naver_urls.append(row['link'])\n",
    "                postdate.append(row['postdate'])\n",
    "                title = row['title']\n",
    "                # html태그제거\n",
    "                pattern1 = '<[^>]*>'\n",
    "                title = re.sub(pattern=pattern1, repl='', string=title)\n",
    "                titles.append(title)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "\n",
    "###naver 기사 본문 및 제목 가져오기###\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "\n",
    "contents = []\n",
    "comments_texts = []\n",
    "try:\n",
    "    for i in naver_urls:\n",
    "        print(i)\n",
    "        driver.get(i)\n",
    "        time.sleep(5)  # 대기시간 변경 가능\n",
    "\n",
    "        iframe = driver.find_element(By.ID , \"mainFrame\") # id가 mainFrame이라는 요소를 찾아내고 -> iframe임\n",
    "        driver.switch_to.frame(iframe) # 이 iframe이 내가 찾고자하는 html을 포함하고 있는 내용\n",
    "\n",
    "        source = driver.page_source\n",
    "        html = BeautifulSoup(source, \"html.parser\")\n",
    "        # 검색결과 확인용\n",
    "        # with open(\"Output.txt\", \"w\") as text_file:\n",
    "        #     text_file.write(str(html))\n",
    "        \n",
    "        # 기사 텍스트만 가져오기\n",
    "        content = html.select(\"div.se-main-container\")\n",
    "        #  list합치기\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # html태그제거 및 텍스트 다듬기\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "        content = content.replace('\\n', '')\n",
    "        content = content.replace('\\u200b', '')\n",
    "        contents.append(content)\n",
    "\n",
    "\n",
    "    news_df = pd.DataFrame({'title': titles, 'content': contents, 'date': postdate})\n",
    "    news_df.to_csv('blog.csv', index=False, encoding='utf-8-sig')\n",
    "except:\n",
    "    contents.append('error')\n",
    "    news_df = pd.DataFrame({'title': titles, 'content': contents, 'date': postdate})\n",
    "    news_df.to_csv('blog.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
